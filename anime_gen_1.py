# -*- coding: utf-8 -*-
"""Anime Character Generation with DCGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KjmgZ5pg8aSHMZJxFEqHN9gafaPVYvyy
"""


import os 
import math
import numpy as np
import matplotlib.pyplot as plt
import cv2
import glob
import time
import os
from PIL import Image

import tensorflow as tf
from keras import Input, Model
from keras.applications import InceptionResNetV2
from keras.callbacks import TensorBoard
from keras.layers import Conv2D, Flatten, Dense, BatchNormalization, Reshape, concatenate, LeakyReLU, Lambda, Conv2DTranspose, Activation, UpSampling2D, Dropout, ReLU, MaxPooling2D
from keras.optimizers import Adam, SGD, RMSprop
from keras.utils import to_categorical
from keras_preprocessing import image
from keras.models import load_model, Sequential
import keras.backend as K

def load_images(src):
  #src= 'anime-faces'
  image_data = []

  for file in os.listdir(src):
    file_path = os.path.join(src, file)
    for image in os.listdir(file_path):
      if not image.startswith('.'):
        img_path = os.path.join(file_path, image)    
        #print(img_path)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (64, 64))
        image_data.append(img)

  image_data = np.asarray(image_data)
  return(image_data)

def build_gen():
  
  
  gen_model = Sequential()
  gen_model.add(Dense(units = 2048))
  gen_model.add(LeakyReLU(alpha = 0.2))
  
  gen_model.add(Dense(256 * 8 * 8))
  gen_model.add(BatchNormalization())
  gen_model.add(LeakyReLU(alpha = 0.2))
  
  gen_model.add(Reshape((8, 8, 256), input_shape = (256 * 8 * 8,)))

  gen_model.add(UpSampling2D(size = (2, 2)))
  gen_model.add(Conv2D(128, (5, 5), padding = 'same'))
  gen_model.add(LeakyReLU(alpha = 0.2))
  
  gen_model.add(UpSampling2D(size = (2, 2)))
  gen_model.add(Conv2D(64, (5, 5), padding = 'same'))
  gen_model.add(LeakyReLU(alpha = 0.2))
  
  gen_model.add(UpSampling2D(size = (2, 2)))
  gen_model.add(Conv2D(3, (5, 5), padding = 'same'))
  gen_model.add(Activation('tanh'))
  
  return gen_model

def build_disc():
  
  disc_model = Sequential()
  
  disc_model.add(Conv2D(128 , (5,5), padding = 'same', input_shape = (64, 64, 3)))
  disc_model.add(LeakyReLU(alpha = 0.2))
  disc_model.add(MaxPooling2D(pool_size = (2, 2)))

  disc_model.add(Conv2D(256 , (5,5), padding = 'same'))
  disc_model.add(LeakyReLU(alpha = 0.2))
  disc_model.add(MaxPooling2D(pool_size = (2, 2)))
  
  disc_model.add(Conv2D(512 , (5,5), padding = 'same'))
  disc_model.add(LeakyReLU(alpha = 0.2))
  disc_model.add(MaxPooling2D(pool_size = (2, 2)))
  
  disc_model.add(Flatten())
  
  disc_model.add(Dense(1024))
  disc_model.add(LeakyReLU(alpha = 0.2))
  
  disc_model.add(Dense(1))
  disc_model.add(Activation('sigmoid'))
  
  return disc_model

def write_log(callback, name, loss, batch_no):

    summary = tf.Summary()
    summary_value = summary.value.add()
    summary_value.simple_value = loss
    summary_value.tag = name
    callback.writer.add_summary(summary, batch_no)
    callback.writer.flush()

def save_rgb_img(img, path):

    fig = plt.figure()
    ax = fig.add_subplot(1, 1, 1)
    ax.imshow(img)
    ax.axis("off")
    ax.set_title("Image")

    plt.savefig(path)
    plt.close()

def train():
  
  epochs = 10000
  batch_size = 128
  z_shape = 100
  lr = 0.0005
  momentum = 0.9
  
  print("Loading Images")
  
  X = load_images('anime-faces')
  X = (X - 127.5)/127.5
  X = X.astype(np.float32)

  print(X.shape)
  
  print("Images Loaded")
  
  #disc_optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)
  #gen_optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)
  disc_optimizer = SGD(lr = lr, momentum = momentum, nesterov = True)
  gen_optimizer = SGD(lr = lr, momentum = momentum, nesterov = True)
  
  if(os.path.isfile("generator.h5")):
    gen_model = load_model("generator.h5")
    print("Generator Loaded")
  else:
    gen_model = build_gen()
    gen_model.compile(loss = 'binary_crossentropy', optimizer = gen_optimizer)
  
  
  if(os.path.isfile("discriminator.h5")):
    disc_model = load_model("discriminator.h5")
    print("Discriminator Loaded")
  else:
    disc_model = build_disc()
    disc_model.compile(loss = 'binary_crossentropy', optimizer = disc_optimizer)
  
  
  adversarial_model = Sequential()
  adversarial_model.add(gen_model)
  disc_model.trainable = False
  adversarial_model.add(disc_model)
  
  adversarial_model.compile(loss = 'binary_crossentropy', optimizer = gen_optimizer)
  
  tensorboard = TensorBoard(log_dir = "logs/{}".format(time.time()), write_images = True, write_grads = True , write_graph = True)
  tensorboard.set_model(gen_model)
  tensorboard.set_model(disc_model)
  
  for epoch in range(epochs):
    
    print("Epoch: ", epoch)
    
    start_time = time.time()
    
    number_of_batches = int(X.shape[0] / batch_size)
    
    print("Number of Batches: ", number_of_batches)
    
    for index in range(number_of_batches):
      
      print("Batch: ", index)
      
      # Training the generator
      
      z_noise = np.random.normal(0, 1, size = (batch_size, z_shape))
      
      image_batch = X[index * batch_size : (index + 1) * batch_size]
      
      generated_images = gen_model.predict_on_batch(z_noise)
      
      y_real = np.ones(batch_size) - np.random.random_sample(batch_size) * 0.2
      
      y_fake = np.random.random_sample(batch_size) * 0.2
      
      disc_loss_real = disc_model.train_on_batch(image_batch, y_real)
      disc_loss_fake = disc_model.train_on_batch(generated_images, y_fake)
      
      disc_loss = (disc_loss_real + disc_loss_fake)/2
      print("Discriminator Loss: ", disc_loss)
      
      
      # Training the adversarial
      
      z_noise = np.random.normal(0, 1, size = (batch_size, z_shape))
      
      gen_label = np.ones(batch_size)

      gen_loss = adversarial_model.train_on_batch(z_noise, gen_label)
      
      print("Generator Loss: ", gen_loss)

    write_log(tensorboard, 'discriminator_loss', np.mean(disc_loss), epoch)
    write_log(tensorboard, 'generator_loss', np.mean(gen_loss), epoch)
      
    if epoch % 2 == 0:
        
      z_noise = np.random.normal(0, 1, size = (batch_size, z_shape))
      gen_images1 = gen_model.predict_on_batch(z_noise)
        
      for index, img in enumerate(gen_images1[:2]):
        save_rgb_img(img, "results/image_generated_{}_{}.png".format(epoch, index))
          
      gen_model.save("generator.h5")
      disc_model.save("discriminator.h5")
        
        
    print("Time:", (time.time() - start_time))

if __name__ == '__main__':
  train()

 